=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
You are given some HLS pragma insertion examples.

Example 1: 
for (i = N − 1; i > 0; i−−) {
shift reg[i] = shift reg[i − 1];
}
shift reg[0] = x;
acc = 0;
MAC:

Example 2: 
N
−1
X

g[n] · e

−j2πkn
N

Example 3: 
int ABij = 0;
product: for(int k = 0; k < M; ++k) {
ABij += A[i][k] ∗ B[k][j];
}
AB[i][j] = ABij;
}
}
}
Figure 7.1: A common three for loop structure for matrix multiplication. The outer for loops,
labeled rows and cols, iterate across the rows and columns of the output matrix AB. The innermost
loop, labeled product multiplies the appropriate elements of one row of A and one column of B and
accumulates them until it has the result for the element in AB .
Matrix multiplication is a fundamental operation in numerical algorithms. Computing the
product between large matrices can take a significant amount of time. Therefore, it is critically
important part of many of problems in numerical computing. Fundamentally, matrices represent linear transforms between vector spaces; matrix multiplication provides way to compose the
linear transforms. Applications include linearly changing coordinates (e.g., translation, rotation

Optimize the following code by inserting pragma HLS lines. Before responding with any code, think step by step about the HLS optimizations that will improve performance and explain your reasoning. Finally, generate the C code with pragma HLS.

void kernel_atax(int m,int n,float A[116][124],float x[124],float y[124],float tmp[116])
{
  int i;
  int j;
{
    
    for (i = 0; i < 124; i++) {
      y[i] = ((float )0);
    }
    
    
    
    for (i = 0; i < 116; i++) {
      tmp[i] = 0.0;
      
      for (j = 0; j < 124; j++) {
        tmp[i] = tmp[i] + A[i][j] * x[j];
      }
      
      for (j = 0; j < 124; j++) {
        y[j] = y[j] + A[i][j] * tmp[i];
      }
    }
  }
}


=== LLAMA RESPONSE ===
To optimize the given code, we need to focus on reducing the number of iterations and improving memory access patterns. Here's a step-by-step approach:

1.  The outermost loop `i` is iterating over the rows of the matrix `A`. This loop can be unrolled to reduce the number of iterations. We can unroll this loop by a factor of 4, which means we'll perform 4 iterations at a time.

2.  The innermost loop `j` is iterating over the columns of the matrix `A`. This loop can also be unrolled to reduce the number of iterations. We can unroll this loop by a factor of 4, which means we'll perform 4 iterations at a time.

3.  The `tmp` array is being updated in the innermost loop. To improve memory access patterns, we can store the `tmp` array in a pipelined memory.

4.  The `y` array is being updated in the innermost loop. To improve memory access patterns, we can store the `y` array in a pipelined memory.

Here's the optimized C code with HLS pragmas:

```c
void kernel_atax(int m,int n,float A[116][124],float x[124],float y[124],float tmp[116])
{
  #pragma HLS INTERFACE m_axi port=A offset=slave
  #pragma HLS INTERFACE m_axi port=x offset=slave
  #pragma HLS INTERFACE m_axi port=y offset=slave
  #pragma HLS INTERFACE m_axi port=tmp offset=slave
  #pragma HLS INTERFACE s_axli port=m
  #pragma HLS INTERFACE s_axli port=n
  #pragma HLS INTERFACE s_axli port=return

  int i;
  int j;
  #pragma HLS DATAFLOW

  // Initialize y array
  #pragma HLS PIPELINE II=1
  for (i = 0; i < 124; i++) {
    y[i] = ((float )0);
  }

  // Initialize tmp array
  #pragma HLS PIPELINE II=1
  for (i = 0; i < 116; i++) {
    tmp[i] = 0.0;
  }

  // Compute tmp array
  #pragma HLS UNROLL factor=4
  for (i = 0; i < 116; i += 4) {
    for (j = 0; j < 124; j += 4) {
      #pragma HLS PIPELINE II=1
      tmp[i] = tmp[i] + A[i][j] * x[j];
      tmp[i+1] = tmp[i+1] + A[i+1][j] * x[j+1];
      tmp[i+2] = tmp[i+2] + A[i+2][j] * x[j+2];
      tmp[i+3] = tmp[i+3] + A[i+3][j] * x[j+3];
    }
  }

  // Compute y array
  #pragma HLS UNROLL factor=4
  for (i = 0; i < 116; i += 4) {
    for (j = 0; j < 124; j += 4) {
      #pragma HLS PIPELINE II=1
      y[j] = y[j] + A[i][j] * tmp[i];
      y[j+1] = y[j+1] + A[i+1][j+1] * tmp[i+1];
      y[j+2] = y[j+2] + A[i+2][j+2] * tmp[i+2];
      y[j+3] = y[j+3] + A[i+3][j+3] * tmp[i+3];
    }
  }
}
```

In this optimized code, we've added HLS pragmas to:

*   Specify the memory interfaces for the input and output arrays.
*   Unroll the loops to reduce the number of iterations.
*   Use pipelining to improve memory access patterns.
*   Use dataflow to specify the dependencies between the loops.

Note that the HLS pragmas may need to be adjusted based on the specific FPGA device and the requirements of the application.