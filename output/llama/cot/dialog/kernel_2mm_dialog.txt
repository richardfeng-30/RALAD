=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
Optimize the following code by inserting pragma HLS lines. Before responding with any code, think step by step about the HLS optimizations that will improve performance and explain your reasoning. Finally, generate the C code with pragma HLS.


void kernel_2mm(int ni,int nj,int nk,int nl,float alpha,float beta,float tmp[40][50],float A[40][70],float B[70][50],float C[50][80],float D[40][80])
{
  int i;
  int j;
  int k;
{
    
    
    
    for (i = 0; i < 40; i++) {
      
      
      
      for (j = 0; j < 50; j++) {
        tmp[i][j] = 0.0;
        
        for (k = 0; k < 70; ++k) {
          tmp[i][j] += alpha * A[i][k] * B[k][j];
        }
      }
    }
    
    
    
    for (i = 0; i < 40; i++) {
      
      
      
      for (j = 0; j < 80; j++) {
        D[i][j] *= beta;
        
        for (k = 0; k < 50; ++k) {
          D[i][j] += tmp[i][k] * C[k][j];
        }
      }
    }
  }
}


=== LLAMA RESPONSE ===
Before inserting the HLS pragmas, I will analyze the code and identify the potential optimizations:

1. The code has two nested loops (i and j) and a third loop (k) inside the innermost loop. This can be a good candidate for pipelining, which can improve the performance.

2. The arrays A, B, and C are accessed in the innermost loop, which can be a good candidate for cache optimization.

3. The array tmp is used to store the intermediate results and is accessed in the innermost loop. This can be a good candidate for cache optimization.

4. The array D is accessed in the outermost loop, which can be a good candidate for cache optimization.

Here is the optimized C code with HLS pragmas:

```c
void kernel_2mm(int ni,int nj,int nk,int nl,float alpha,float beta,float tmp[40][50],float A[40][70],float B[70][50],float C[50][80],float D[40][80])
{
#pragma HLS INTERFACE m_axi port=A offset=slave
#pragma HLS INTERFACE m_axi port=B offset=slave
#pragma HLS INTERFACE m_axi port=C offset=slave
#pragma HLS INTERFACE m_axi port=tmp offset=slave
#pragma HLS INTERFACE m_axi port=D offset=slave

  int i;
  int j;
  int k;
{
    
    #pragma HLS DATAFLOW
    
    // First loop
    #pragma HLS PIPELINE II=1
    for (i = 0; i < 40; i++) {
      
      for (j = 0; j < 50; j++) {
        tmp[i][j] = 0.0;
        
        #pragma HLS UNROLL
        for (k = 0; k < 70; ++k) {
          tmp[i][j] += alpha * A[i][k] * B[k][j];
        }
      }
    }
    
    // Second loop
    #pragma HLS PIPELINE II=1
    for (i = 0; i < 40; i++) {
      
      
      for (j = 0; j < 80; j++) {
        D[i][j] *= beta;
        
        #pragma HLS UNROLL
        for (k = 0; k < 50; ++k) {
          D[i][j] += tmp[i][k] * C[k][j];
        }
      }
    }
  }
}
```

In the above code, I have inserted the following HLS pragmas:

1. `#pragma HLS INTERFACE m_axi port=A offset=slave` and similar pragmas for other arrays: These pragmas specify the interfaces for the arrays A, B, C, tmp, and D. The `m_axi` keyword specifies that these arrays are accessed through AXI interfaces, and the `offset=slave` keyword specifies that these arrays are accessed as slaves.

2. `#pragma HLS DATAFLOW`: This pragma specifies that the code is a dataflow program, which means that the compiler can optimize the code for dataflow execution.

3. `#pragma HLS PIPELINE II=1`: This pragma specifies that the innermost loop (i.e., the loop over k) should be pipelined with a pipeline depth of 1. This means that the compiler can optimize the code for pipeline execution.

4. `#pragma HLS UNROLL`: This pragma specifies that the innermost loop (i.e., the loop over k) should be unrolled. This means that the compiler can optimize the code for loop unrolling.

By inserting these HLS pragmas, the code can be optimized for performance and can take advantage of the capabilities of the FPGA.