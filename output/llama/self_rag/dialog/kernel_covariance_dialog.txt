=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
You are given some HLS pragma insertion examples.

Example 1: 
// Write out resulting row of C
    for (int m = 0; m < M; ++m) {
      #pragma HLS PIPELINE II=1
      C[n * M + m] = acc[m];
    }
  }
}



Example 6
This example plays with scaling up parallelism in a matrix multiplication example. We add two degrees of parallelism: horizontal vector parallelism, which consumes bandwidth, and pipeline parallelism, which consumes buffer space. In xilinx/Example6.cpp, rather than loading a single value of a before the inner M-loop, we load a higher (parametric) number of elements, allowing us to apply each of them to every value of B loaded. In xilinx/Example6_Vectorized.cpp, we additionally add vectorization, by replacing the primitive data types with vector types, and adjusting the loop bounds accordingly. The two files can be synthesized with make synthesize_example6 and make synthesize_example6_vectorized, respectively.

Optimize the following code by inserting pragma HLS lines.
//Covariance Computation


void kernel_covariance(int m,int n,float float_n,float data[100][80],float cov[80][80],float mean[80])
{
  int i;
  int j;
  int k;
{
    
    
    
    for (j = 0; j < 80; j++) {
      mean[j] = 0.0;
      
      for (i = 0; i < 100; i++) {
        mean[j] += data[i][j];
      }
      mean[j] /= float_n;
    }
    
    
    
    for (i = 0; i < 100; i++) {
      
      for (j = 0; j < 80; j++) {
        data[i][j] -= mean[j];
      }
    }
    
    
    
    for (i = 0; i < 80; i++) {
      
      for (j = i; j < 80; j++) {
        cov[i][j] = 0.0;
        
        for (k = 0; k < 100; k++) {
          cov[i][j] += data[k][i] * data[k][j];
        }
        cov[i][j] /= float_n - 1.0;
        cov[j][i] = cov[i][j];
      }
    }
  }
}


=== LLAMA RESPONSE ===
Here is the optimized code with HLS pragmas:

```c
void kernel_covariance(int m, int n, float float_n, float data[100][80], float cov[80][80], float mean[80]) {
  #pragma HLS INTERFACE m_axi port=data offset=slave bundle=gmem
  #pragma HLS INTERFACE m_axi port=cov offset=slave bundle=gmem
  #pragma HLS INTERFACE m_axi port=mean offset=slave bundle=gmem

  int i;
  int j;
  int k;

  for (j = 0; j < 80; j++) {
    mean[j] = 0.0;
    #pragma HLS PIPELINE II=1
    for (i = 0; i < 100; i++) {
      mean[j] += data[i][j];
    }
    mean[j] /= float_n;
  }

  for (i = 0; i < 100; i++) {
    #pragma HLS LOOP_TRIPCOUNT min=100 max=100
    #pragma HLS PIPELINE II=1
    for (j = 0; j < 80; j++) {
      data[i][j] -= mean[j];
    }
  }

  for (i = 0; i < 80; i++) {
    #pragma HLS LOOP_TRIPCOUNT min=80 max=80
    for (j = i; j < 80; j++) {
      cov[i][j] = 0.0;
      #pragma HLS PIPELINE II=1
      for (k = 0; k < 100; k++) {
        cov[i][j] += data[k][i] * data[k][j];
      }
      cov[i][j] /= float_n - 1.0;
      cov[j][i] = cov[i][j];
    }
  }
}
```

In this code, I added the following HLS pragmas:

* `#pragma HLS INTERFACE m_axi` to specify the interface for the input and output arrays.
* `#pragma HLS PIPELINE II=1` to specify a pipeline with a latency of 1 clock cycle.
* `#pragma HLS LOOP_TRIPCOUNT min=... max=...` to specify the minimum and maximum trip count for the loops.

These pragmas can help the HLS compiler to optimize the code for better performance and resource utilization.