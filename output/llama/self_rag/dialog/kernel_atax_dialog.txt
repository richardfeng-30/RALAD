=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
You are given some HLS pragma insertion examples.

Example 1: 
// Write out resulting row of C
    for (int m = 0; m < M; ++m) {
      #pragma HLS PIPELINE II=1
      C[n * M + m] = acc[m];
    }
  }
}



Example 6
This example plays with scaling up parallelism in a matrix multiplication example. We add two degrees of parallelism: horizontal vector parallelism, which consumes bandwidth, and pipeline parallelism, which consumes buffer space. In xilinx/Example6.cpp, rather than loading a single value of a before the inner M-loop, we load a higher (parametric) number of elements, allowing us to apply each of them to every value of B loaded. In xilinx/Example6_Vectorized.cpp, we additionally add vectorization, by replacing the primitive data types with vector types, and adjusting the loop bounds accordingly. The two files can be synthesized with make synthesize_example6 and make synthesize_example6_vectorized, respectively.

Example 2: 
7.2 Complete Matrix Multiplication
We start our optimization process with perhaps the most common method to compute a matrix
multiplication – using three nested for loops. Figure 7.1 provides the code for such an implementation. The outer for loops, labeled rows and cols, iterate across the rows and columns of the output
matrix AB. The innermost for loop computes a dot product of one row of A and one column of
B. Each dot product is a completely independent set of computations that results in one element
of AB. Conceptually, we are performing P matrix-vector multiplications, one for each column of
B.
In this case, we’ve applied a pipeline directive to the col loop with a target initiation interval of 1.
The result is that the innermost for loop is fully unrolled, and we expect the resulting circuit include
roughly M multiply-add operators and to have an interval of roughly N ∗ P cycles. As discussed

Optimize the following code by inserting pragma HLS lines.
//Matrix Transpose and Vector Multiplication


void kernel_atax(int m,int n,float A[116][124],float x[124],float y[124],float tmp[116])
{
  int i;
  int j;
{
    
    for (i = 0; i < 124; i++) {
      y[i] = ((float )0);
    }
    
    
    
    for (i = 0; i < 116; i++) {
      tmp[i] = 0.0;
      
      for (j = 0; j < 124; j++) {
        tmp[i] = tmp[i] + A[i][j] * x[j];
      }
      
      for (j = 0; j < 124; j++) {
        y[j] = y[j] + A[i][j] * tmp[i];
      }
    }
  }
}


=== LLAMA RESPONSE ===
Here is the optimized code with HLS pragmas:

```c
void kernel_atax(int m, int n, float A[116][124], float x[124], float y[124], float tmp[116])
{
  int i;
  int j;

  #pragma HLS INTERFACE m_axi port=A offset=slave
  #pragma HLS INTERFACE m_axi port=x offset=slave
  #pragma HLS INTERFACE m_axi port=y offset=slave
  #pragma HLS INTERFACE m_axi port=tmp offset=slave
  #pragma HLS INTERFACE s_axli port=m
  #pragma HLS INTERFACE s_axli port=n
  #pragma HLS INTERFACE s_axli port=y
  #pragma HLS INTERFACE s_axli port=tmp
  #pragma HLS INTERFACE s_axli port=A
  #pragma HLS INTERFACE s_axli port=x
  #pragma HLS DATAFLOW

  #pragma HLS PIPELINE II=1
  for (i = 0; i < 116; i++) {
    tmp[i] = 0.0;
    
    #pragma HLS LOOP_TRIPCOUNT min=116 max=116
    #pragma HLS UNROLL
    for (j = 0; j < 124; j++) {
      tmp[i] = tmp[i] + A[i][j] * x[j];
    }
    
    #pragma HLS LOOP_TRIPCOUNT min=124 max=124
    for (j = 0; j < 124; j++) {
      y[j] = y[j] + A[i][j] * tmp[i];
    }
  }
}
```

Explanation:
- `#pragma HLS INTERFACE m_axi port=<variable> offset=slave` is used to specify the memory interface for the variables.
- `#pragma HLS DATAFLOW` is used to specify that the function is a dataflow function.
- `#pragma HLS PIPELINE II=<interval>` is used to specify the pipeline initiation interval.
- `#pragma HLS LOOP_TRIPCOUNT min=<min> max=<max>` is used to specify the loop trip count.
- `#pragma HLS UNROLL` is used to specify that the loop should be unrolled.