=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
You are given some HLS pragma insertion examples.

Example 1: 
// Write out resulting row of C
    for (int m = 0; m < M; ++m) {
      #pragma HLS PIPELINE II=1
      C[n * M + m] = acc[m];
    }
  }
}



Example 6
This example plays with scaling up parallelism in a matrix multiplication example. We add two degrees of parallelism: horizontal vector parallelism, which consumes bandwidth, and pipeline parallelism, which consumes buffer space. In xilinx/Example6.cpp, rather than loading a single value of a before the inner M-loop, we load a higher (parametric) number of elements, allowing us to apply each of them to every value of B loaded. In xilinx/Example6_Vectorized.cpp, we additionally add vectorization, by replacing the primitive data types with vector types, and adjusting the loop bounds accordingly. The two files can be synthesized with make synthesize_example6 and make synthesize_example6_vectorized, respectively.

Example 2: 
// Stream row of B and apply it to the stored value of A
        for (int tm = 0; tm < TM; ++tm) {
          #pragma HLS PIPELINE II=1
          const auto b_read = b_in.Pop();
          const auto c_prev = (k > 0) ? c_buffer[tm] : Vec_t{static_cast<float>(0.)};
          c_buffer[tm] = c_prev + a_buffer * b_read;
          #pragma HLS DEPENDENCE variable=c_buffer false
          // Forward to subsequent PE, if any
          if (d < D - 1) {
            b_out.Push(b_read);
          }
        }

      } // End loop over K

      // Write out result block
      for (int tn = 0; tn < d + 1; ++tn) { // Different for each PE
        for (int tm = 0; tm < TM; ++tm) {
          #pragma HLS PIPELINE II=1
          #pragma HLS LOOP_FLATTEN
          Vec_t c_val{};
          if (d > 0 && tn > 0) {
            c_val = c_in.Pop();
          } else {
            c_val = c_buffer[tm];
          }
          c_out.Push(c_val);
        }
      }
    }
  }
}

Example 3: 
// Burst read for matrix A
// Auto-pipeline is going to apply pipeline to these loops
readA:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
#pragma HLS LOOP_TRIPCOUNT min = c_dim* c_dim max = c_dim * c_dim
        if (j == dim) {
            j = 0;
            i++;
        }
        A[i * MAX_DIM + j] = in1[itr];
    }

// Burst read for matrix B
readB:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
#pragma HLS LOOP_TRIPCOUNT min = c_dim* c_dim max = c_dim * c_dim
        if (j == dim) {
            j = 0;
            i++;
        }
        B[i * MAX_DIM + j] = in2[itr];
    }

Optimize the following code by inserting pragma HLS lines.
//Heat Equation over 3D Data Domain


void kernel_heat_3d(int tsteps,int n,float A[20][20][20],float B[20][20][20])
{
  int t;
  int i;
  int j;
  int k;
{
    
    
    
    for (t = 1; t <= 40; t++) {
      
      
      for (i = 1; i < 20 - 1; i++) {
        
        
        for (j = 1; j < 20 - 1; j++) {
          for (k = 1; k < 20 - 1; k++) {
            B[i][j][k] = 0.125 * (A[i + 1][j][k] - 2.0 * A[i][j][k] + A[i - 1][j][k]) + 0.125 * (A[i][j + 1][k] - 2.0 * A[i][j][k] + A[i][j - 1][k]) + 0.125 * (A[i][j][k + 1] - 2.0 * A[i][j][k] + A[i][j][k - 1]) + A[i][j][k];
          }
        }
      }
      
      
      for (i = 1; i < 20 - 1; i++) {
        
        
        for (j = 1; j < 20 - 1; j++) {
          for (k = 1; k < 20 - 1; k++) {
            A[i][j][k] = 0.125 * (B[i + 1][j][k] - 2.0 * B[i][j][k] + B[i - 1][j][k]) + 0.125 * (B[i][j + 1][k] - 2.0 * B[i][j][k] + B[i][j - 1][k]) + 0.125 * (B[i][j][k + 1] - 2.0 * B[i][j][k] + B[i][j][k - 1]) + B[i][j][k];
          }
        }
      }
    }
  }
}


=== LLAMA RESPONSE ===
Here is the optimized code with HLS pragmas:
```c
void kernel_heat_3d(int tsteps, int n, float A[20][20][20], float B[20][20][20]) {
  int t;
  int i;
  int j;
  int k;

  #pragma HLS INTERFACE m_axi port=A offset=slave
  #pragma HLS INTERFACE m_axi port=B offset=slave

  for (t = 1; t <= 40; t++) {
    #pragma HLS PIPELINE II=1

    for (i = 1; i < 20 - 1; i++) {
      #pragma HLS UNROLL factor=4
      for (j = 1; j < 20 - 1; j++) {
        #pragma HLS UNROLL factor=4
        for (k = 1; k < 20 - 1; k++) {
          #pragma HLS DEPENDENCE variable=B[i][j][k] false
          B[i][j][k] = 0.125 * (A[i + 1][j][k] - 2.0 * A[i][j][k] + A[i - 1][j][k]) + 0.125 * (A[i][j + 1][k] - 2.0 * A[i][j][k] + A[i][j - 1][k]) + 0.125 * (A[i][j][k + 1] - 2.0 * A[i][j][k] + A[i][j][k - 1]) + A[i][j][k];
        }
      }
    }

    #pragma HLS PIPELINE II=1

    for (i = 1; i < 20 - 1; i++) {
      #pragma HLS UNROLL factor=4
      for (j = 1; j < 20 - 1; j++) {
        #pragma HLS UNROLL factor=4
        for (k = 1; k < 20 - 1; k++) {
          #pragma HLS DEPENDENCE variable=A[i][j][k] false
          A[i][j][k] = 0.125 * (B[i + 1][j][k] - 2.0 * B[i][j][k] + B[i - 1][j][k]) + 0.125 * (B[i][j + 1][k] - 2.0 * B[i][j][k] + B[i][j - 1][k]) + 0.125 * (B[i][j][k + 1] - 2.0 * B[i][j][k] + B[i][j][k - 1]) + B[i][j][k];
        }
      }
    }
  }
}
```
Here's a brief explanation of the pragmas used:

* `#pragma HLS INTERFACE m_axi`: This pragma specifies the AXI4 interface for the `A` and `B` arrays.
* `#pragma HLS PIPELINE II=1`: This pragma enables pipeline parallelism for the loops, with a pipeline depth of 1.
* `#pragma HLS UNROLL factor=4`: This pragma unrolls the loops with a factor of 4, which can improve performance by reducing the number of iterations.
* `#pragma HLS DEPENDENCE variable=<variable> false`: This pragma specifies that the variable is not dependent on any other variables, which can help the HLS compiler optimize the code better.

Note that the pragmas used here are just suggestions and may need to be adjusted based on the specific requirements of your design and the capabilities of your FPGA.