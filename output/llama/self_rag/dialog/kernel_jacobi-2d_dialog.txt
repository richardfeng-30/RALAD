=== SYSTEM ===
Always answer with optimized C code including HLS pragmas. Add appropriate #pragma HLS directives for interfaces, loops, and memory optimization.

=== USER QUERY ===
You are given some HLS pragma insertion examples.

Example 1: 
// Burst write from output matrices to global memory
// Burst write from matrix C
writeC:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
#pragma HLS LOOP_TRIPCOUNT min = c_dim* c_dim max = c_dim * c_dim
        if (j == dim) {
            j = 0;
            i++;
        }
        out_r[itr] = C[i * MAX_DIM + j];
    }
}


================================================================================
Example: Array/array_partition_complete
================================================================================
--- README ---
This is a simple example of matrix multiplication (Row x Col) to demonstrate complete array partitioning pragma in HLS

Running the Design using Vitis HLS (edit run_hls.tcl to set $hls_exec and enable specific run steps)
=========================================================
vitis-run --mode hls --tcl run_hls.tcl

Example 2: 
// Write out resulting row of C
    for (int m = 0; m < M; ++m) {
      #pragma HLS PIPELINE II=1
      C[n * M + m] = acc[m];
    }
  }
}



Example 6
This example plays with scaling up parallelism in a matrix multiplication example. We add two degrees of parallelism: horizontal vector parallelism, which consumes bandwidth, and pipeline parallelism, which consumes buffer space. In xilinx/Example6.cpp, rather than loading a single value of a before the inner M-loop, we load a higher (parametric) number of elements, allowing us to apply each of them to every value of B loaded. In xilinx/Example6_Vectorized.cpp, we additionally add vectorization, by replacing the primitive data types with vector types, and adjusting the loop bounds accordingly. The two files can be synthesized with make synthesize_example6 and make synthesize_example6_vectorized, respectively.

Optimize the following code by inserting pragma HLS lines.
//2-D Jacobi Stencil Computation

void kernel_jacobi_2d(int tsteps,int n,float A[90][90],float B[90][90])
{
  int t;
  int i;
  int j;
{
    
    
    
    for (t = 0; t < 40; t++) {
      
      
      
      for (i = 1; i < 90 - 1; i++) {
        
        for (j = 1; j < 90 - 1; j++) {
          B[i][j] = 0.2 * (A[i][j] + A[i][j - 1] + A[i][1 + j] + A[1 + i][j] + A[i - 1][j]);
        }
      }
      
      
      
      for (i = 1; i < 90 - 1; i++) {
        
        for (j = 1; j < 90 - 1; j++) {
          A[i][j] = 0.2 * (B[i][j] + B[i][j - 1] + B[i][1 + j] + B[1 + i][j] + B[i - 1][j]);
        }
      }
    }
  }
}


=== LLAMA RESPONSE ===
Here is the optimized code with HLS pragmas:
```
void kernel_jacobi_2d(int tsteps, int n, float A[90][90], float B[90][90]) {
  int t;
  int i;
  int j;

  #pragma HLS INTERFACE m_axi port=A offset=slave bundle=gmem
  #pragma HLS INTERFACE m_axi port=B offset=slave bundle=gmem

  #pragma HLS DATAFLOW

  for (t = 0; t < 40; t++) {
    #pragma HLS LOOP_TRIPCOUNT min = 40 max = 40
    #pragma HLS PIPELINE II=1

    for (i = 1; i < 90 - 1; i++) {
      #pragma HLS LOOP_TRIPCOUNT min = 88 max = 88
      #pragma HLS UNROLL factor=4

      for (j = 1; j < 90 - 1; j++) {
        #pragma HLS UNROLL factor=4
        B[i][j] = 0.2 * (A[i][j] + A[i][j - 1] + A[i][1 + j] + A[1 + i][j] + A[i - 1][j]);
      }
    }

    for (i = 1; i < 90 - 1; i++) {
      #pragma HLS LOOP_TRIPCOUNT min = 88 max = 88
      #pragma HLS UNROLL factor=4

      for (j = 1; j < 90 - 1; j++) {
        #pragma HLS UNROLL factor=4
        A[i][j] = 0.2 * (B[i][j] + B[i][j - 1] + B[i][1 + j] + B[1 + i][j] + B[i - 1][j]);
      }
    }
  }
}
```
Here's a brief explanation of the pragmas used:

* `#pragma HLS INTERFACE m_axi` specifies the memory interface for the input/output arrays `A` and `B`.
* `#pragma HLS DATAFLOW` indicates that the kernel is a dataflow kernel, which allows the compiler to optimize the kernel for dataflow.
* `#pragma HLS LOOP_TRIPCOUNT` specifies the minimum and maximum trip count for the loops, which helps the compiler optimize the kernel for the specified range of iterations.
* `#pragma HLS PIPELINE II=1` specifies a pipeline with an initial increment of 1, which allows the compiler to optimize the kernel for pipelining.
* `#pragma HLS UNROLL factor=4` specifies unrolling the loops by a factor of 4, which allows the compiler to optimize the kernel for parallelism.

Note that the pragmas are used to guide the compiler in optimizing the kernel for performance, but the actual optimization may vary depending on the specific hardware and compiler used.