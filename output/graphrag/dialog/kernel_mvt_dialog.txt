### Summary of Relevant Optimization Strategies and Pragmas for HLS

To optimize the given kernel for performance while controlling resource utilization and compilation time, several High-Level Synthesis (HLS) optimization strategies and pragmas can be applied:

1. **Loop Pipelining**: Applying `#pragma HLS pipeline` to loops can improve throughput by initiating new iterations before previous ones complete, reducing the initiation interval (II). This is critical for nested loops to enhance concurrency.

2. **Loop Unrolling**: Using `#pragma HLS unroll` on inner loops can increase parallelism by replicating hardware resources, but it increases area. Partial unrolling with a factor can balance performance and resource usage.

3. **Array Partitioning**: Partitioning arrays with `#pragma HLS array_partition` can improve memory bandwidth by enabling parallel access to array elements, which is often a bottleneck in matrix operations.

4. **Loop Flattening**: `#pragma HLS loop_flatten` can be used to flatten nested loops into a single loop, which sometimes improves pipeline efficiency.

5. **Dataflow Optimization**: For kernels with multiple independent loops, `#pragma HLS dataflow` can enable concurrent execution of different loops or functions, improving overall throughput.

6. **Resource Constraints and Pragmas**: To keep resource utilization under 80%, careful use of partial unrolling and selective array partitioning is necessary. Full unrolling may exceed resource limits.

7. **Pragma Placement**: Pragmas should be placed inside the function, directly before the loops or arrays they optimize.

These strategies are commonly used in Vitis HLS and Vivado HLS to optimize matrix-vector multiplication and similar kernels [Data: Entities (213, 4955, 4337, 357); Relationships (97, 98, 96, 103, 105, 106)].

---

### Optimized Code with Pragmas Inserted

```c
void kernel_mvt(int n, float x1[120], float x2[120], float y_1[120], float y_2[120], float A[120][120])
{
    int i, j;

    // Partition arrays to enable parallel access and reduce memory bottlenecks
    #pragma HLS array_partition variable=A complete dim=2
    #pragma HLS array_partition variable=y_1 complete
    #pragma HLS array_partition variable=y_2 complete

    // First matrix-vector multiplication loop
    for (i = 0; i < 120; i++) {
        #pragma HLS pipeline II=1
        float sum1 = 0;
        for (j = 0; j < 120; j++) {
            #pragma HLS unroll factor=4
            sum1 += A[i][j] * y_1[j];
        }
        x1[i] += sum1;
    }

    // Second matrix-vector multiplication loop
    for (i = 0; i < 120; i++) {
        #pragma HLS pipeline II=1
        float sum2 = 0;
        for (j = 0; j < 120; j++) {
            #pragma HLS unroll factor=4
            sum2 += A[j][i] * y_2[j];
        }
        x2[i] += sum2;
    }
}
```

---

### Explanation of Applied Pragmas

- **Array Partitioning**: The matrix `A` is partitioned completely along the second dimension (`dim=2`), allowing simultaneous access to multiple columns in each row. The vectors `y_1` and `y_2` are fully partitioned to enable parallel reads, which is essential for unrolling the inner loop.

- **Loop Pipelining**: The outer loops over `i` are pipelined with an initiation interval (II) of 1, aiming to start a new iteration every clock cycle, maximizing throughput.

- **Loop Unrolling**: The inner loops over `j` are partially unrolled by a factor of 4 to balance parallelism and resource usage. Full unrolling (factor=120) would likely exceed the 80% resource utilization constraint.

- **Local Accumulators**: Using local variables `sum1` and `sum2` to accumulate results avoids repeated memory accesses to `x1[i]` and `x2[i]` inside the inner loop, improving performance.

This combination of pragmas and restructuring is a common best practice to optimize matrix-vector multiplication kernels in HLS, improving throughput while controlling resource usage and compilation time [Data: Entities (213, 4955, 4337, 357); Relationships (97, 98, 103, 105, 106)].

---

If further resource constraints or performance targets are specified, additional tuning of unroll factors or array partitioning granularity can be performed.